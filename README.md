# Extraindo dados do site do g1 rss e salvando not√≠cias em arquivo docx, usando rabbitmq (Padr√£o WORK QUEUE)

## 1. Objetivo do projeto

O objetivo deste projeto √© demonstrar uma arquitetura distribu√≠da de web scraping para coletar dados de uma URL RSS (ex: [G1 Ribeir√£o Preto-Franca](https://g1.globo.com/rss/g1/sp/ribeirao-preto-franca/)), obter a not√≠cia do site (ex: [exemplo de not√≠cia](https://g1.globo.com/sp/ribeirao-preto-franca/noticia/2025/08/16/advogado-escapa-ileso-de-ataque-a-tiros-em-ribeirao-preto-video.ghtml)) e salvar o texto em arquivos DOCX.  

O projeto realiza processamento de dados em paralelo e explora os seguintes conceitos e tecnologias:

- Padr√£o Work Queue com RabbitMQ
- Banco de dados n√£o relacional Redis

---

## 2. Tecnologias utilizadas

- **Python** ‚Äì Linguagem principal para scraping, processamento e integra√ß√£o.  
- **RabbitMQ** ‚Äì Sistema de mensageria para coordenar o fluxo de not√≠cias.  
- **Requests + BeautifulSoup** ‚Äì Para baixar e extrair o conte√∫do das mat√©rias.  
- **python-docx** ‚Äì Para salvar as not√≠cias em arquivos DOCX.  
- **Docker Compose** ‚Äì Para empacotamento e execu√ß√£o dos servi√ßos.  
- **Redis** ‚Äì Banco de dados para armazenar URLs de not√≠cias e evitar duplicidade.

---

## 3. Arquitetura da solu√ß√£o

O web scraping distribu√≠do foi dividido em duas fun√ß√µes principais:

1. **Producer**: l√™ a URL RSS do G1, obt√©m o link da not√≠cia e envia para a fila do RabbitMQ.  
2. **Consumer (Workers)**: recebem os links da fila, extraem o texto da not√≠cia e salvam em um arquivo DOCX.

---

### 3.1 Requisitos do projeto

#### 3.1.1 Requisitos Funcionais

- **RF1** ‚Äì Coleta de links de not√≠cias do site do G1 via RSS  
- **RF2** ‚Äì Publica√ß√£o dos links na fila, ex: `fila_g1_ribeirao_preto`  
- **RF3** ‚Äì Consumers recebem os links das not√≠cias  
- **RF4** ‚Äì Arquivo DOCX gerado com o t√≠tulo da not√≠cia, ex:  Site: **https://g1.globo.com/sp/ribeirao-preto-franca/especial-publicitario/ampere-inteligencia-em-eventos/noticia/2025/08/12/eventos-corporativos-presenciais-sao-estrategicos-para-engajar-clientes-e-equipes.ghtml** Nome do arquivo: **eventos_corporativos_presenciais_sao_estrategicos_para_engajar_clientes_e_equipes.docx**
- **RF5** ‚Äì Cada not√≠cia fica em uma pasta/diret√≥rio de acordo com o nome da fila.

#### 3.1.2 Requisitos N√£o Funcionais

- **RNF1** ‚Äì Suportar aumento do n√∫mero de consumers sem mudan√ßas significativas no c√≥digo  
- **RNF2** ‚Äì Processamento de cada not√≠cia em tempo satisfat√≥rio: ~3 segundos por worker

---

### 3.2 Diagrama de classes e padr√µes de projeto usados

[![Diagrama de Classe](https://github.com/rodrigorocha1/web_scraping_g1_rabbitmq/blob/master/diagramas/diagrama_de_classe.jpg?raw=true)](https://github.com/rodrigorocha1/web_scraping_g1_rabbitmq/blob/master/diagramas/diagrama_de_classe.jpg?raw=true)

- **Observer / Work Queue**  
Cada worker processa uma mensagem por vez. Se houver falha na extra√ß√£o ou gera√ß√£o do arquivo, a mensagem vai para a **DLQ (Dead Letter Queue)**.

- **Decorator**  
Na classe `ArquivoDOCX`, antes de salvar, √© feita a formata√ß√£o da not√≠cia: t√≠tulo, subt√≠tulo, autor e texto, aplicando estilos (cores, fontes e alinhamento).

- **Repository**  
A classe `ConexaRedis` abstrai opera√ß√µes de leitura e consulta, isolando a l√≥gica de persist√™ncia no Redis.

- **Template Method**  
Presente em `IwebScapingBase` e `WebScrapingBs4Base`. Define o fluxo de web scraping, permitindo que subclasses (`WebScrapingBs4G1Rss`, `WebScrapingG1`) implementem a l√≥gica espec√≠fica de cada site.

---

### Uso do Redis

- Atua como cache e controle de duplicidade.  
- Estrutura **Set**: cole√ß√£o ordenada de elementos que garante que cada URL seja armazenada apenas uma vez.

---

## 4. Fluxo resumido

1. Producer consulta o RSS do G1  
2. Links de novas not√≠cias s√£o publicados na fila RabbitMQ  
3. Consumers leem os links da fila  
4. Cada consumer baixa a not√≠cia e extrai t√≠tulo, data e conte√∫do  
5. A not√≠cia √© armazenada em um arquivo `.docx`, organizada por data  

---

## 5. Benef√≠cios do projeto

- **Escalabilidade** ‚Äì Poss√≠vel aumentar o n√∫mero de consumers para processar mais not√≠cias em paralelo  
- **Desacoplamento** ‚Äì Producer e consumer n√£o precisam conhecer a l√≥gica entre si  
- **Reuso** ‚Äì Arquitetura reaproveit√°vel para outros sites e formatos  
- **Portf√≥lio** ‚Äì Demonstra integra√ß√£o entre scraping, mensageria e gera√ß√£o de documentos

---



## 6. V√≠deo com a demonstra√ß√£o do projeto 

[![Assistir ao v√≠deo de demonstra√ß√£o do projeto](https://img.shields.io/badge/üé¨%20Assistir%20ao%20v√≠deo-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtu.be/S-rt9kp7MdY)



[Link do repos√≠t√≥rio](https://github.com/rodrigorocha1/web_scraping_g1_rabbitmq)